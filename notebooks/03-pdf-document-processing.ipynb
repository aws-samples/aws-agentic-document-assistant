{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48efd6e-52ed-4499-aedf-2ed70b7b69b8",
   "metadata": {},
   "source": [
    "# 03 - Document processing: PDF to Plaintext and tables\n",
    "This notebook will help you to convert your PDF documents into plaintext.\n",
    "\n",
    "Requirements:\n",
    "- The PDF documents need to be stored in an S3 bucket\n",
    "- Access to AWS Textract\n",
    "\n",
    "Features:\n",
    "- Supports electronic and scanned PDF documents\n",
    "- Also extracts tables included in your PDF documents\n",
    "\n",
    "Limitations:\n",
    "- Pages are processed seperately and hence context from one page to another can be lost, multi-page tables are not extracted correctly for the same reason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181bdbc9-eeb9-4498-a174-e48abe2afe5f",
   "metadata": {},
   "source": [
    "To demonstrate the use case we have made some documents available that you can use. <br>\n",
    "These documents are the annual reports of several large marine logistics companies and they can be found in the `financial_reports` folder.\n",
    "If the `financial_reports` folder is empty or absent, run the `02-download-raw-pdf-documents` notebook to download the sample documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b358e-8cf0-43f1-abd8-3b64c971a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "\n",
    "# Method that will upload the financial reports to S3\n",
    "def upload_files_with_metadata(bucket_name, s3_key_base, prepared_pdfs_metadata):\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "\n",
    "    for pdf_metadata in prepared_pdfs_metadata:\n",
    "        local_file_path = pdf_metadata[\"local_pdf_path\"]\n",
    "        del pdf_metadata[\"local_pdf_path\"]\n",
    "        # Prepare S3 object key with the same folder structure\n",
    "        company = pdf_metadata[\"company\"]\n",
    "        filename = local_file_path.split(\"/\")[-1]\n",
    "        s3_object_key = os.path.join(s3_key_base, company, filename)\n",
    "        print(pdf_metadata)\n",
    "\n",
    "        pdf_metadata[\"pages_kept\"] = str(pdf_metadata[\"pages_kept\"])\n",
    "        # Upload the file to S3 with metadata\n",
    "        with open(local_file_path, \"rb\") as f:\n",
    "            s3_client.upload_fileobj(\n",
    "                f, bucket_name, s3_object_key, ExtraArgs={\"Metadata\": pdf_metadata}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ba8c7-5d9a-4dff-995d-6ad37acc4555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "ssm_client = boto3.client(\"ssm\")\n",
    "\n",
    "s3_bucket_name_parameter = \"/AgenticLLMAssistant/AgentDataBucketParameter\"\n",
    "\n",
    "S3_BUCKET_NAME = ssm_client.get_parameter(Name=s3_bucket_name_parameter)\n",
    "S3_BUCKET_NAME = S3_BUCKET_NAME[\"Parameter\"][\"Value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196001f-763f-4154-83a0-5b987bd67113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the financial reports to your bucket in S3 and add relevant metadata\n",
    "s3_key_base = \"prepared_pdf_documents\"\n",
    "# prepared_base_directory = \"financial_reports/prepared/\"\n",
    "raw_base_directory = \"raw_documents\"\n",
    "prepared_base_directory = os.path.join(raw_base_directory, \"prepared/\")\n",
    "prepared_base_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c1b1ec-ef4b-407a-9d99-93f0ee4880cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\n",
    "    os.path.join(prepared_base_directory, \"metadata.json\"), \"r\"\n",
    ") as prepared_pdfs_metadata_obj:\n",
    "    prepared_pdfs_metadata = json.load(prepared_pdfs_metadata_obj)\n",
    "\n",
    "prepared_pdfs_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f0bce-c018-45e8-aa53-652e301567e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls {prepared_base_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c76a4-4285-4d5c-98b6-e1119d1baae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upload_files_with_metadata(S3_BUCKET_NAME, s3_key_base, prepared_pdfs_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a7cf8-0682-4699-8bac-ce0fba0d0dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 ls {S3_BUCKET_NAME}/prepared_pdf_documents/Amazon/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7926e7e6-856c-4e0a-81e2-07c8f49e082e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define methods to extract data from PDF documents in S3\n",
    "\n",
    "A high level overview of the logic is that:\n",
    "\n",
    "1. We start a Textract analysis job for each of the documents in the S3 bucket using `start_analysis_jobs` and monitor their progress using `check_jobs_status` method.\n",
    "2. When they are done, we get the results using `get_job_results` which consolidates the results of the jobs and ensures that for each document we have all the extracted text for each page, seperately.\n",
    "3. The `extract_text` and `extract_tables` methods extract the text and tables present on a page.\n",
    "4. The `detect_groups` method uses clustering to determine clusters of text on the page.\n",
    "5. the found clusters are then ordered left to right and top to bottom to determine the reading order on the page.\n",
    "\n",
    "This process is depicted below:\n",
    "\n",
    "![pdf to plain text](./assets/pdf-to-plain-text.png)|\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce80e4e-1719-4a0a-b9c2-29f79b9a3b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"textract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa47c5b5-db21-46de-a5d0-df22fbc10d8a",
   "metadata": {},
   "source": [
    "#### Method to start the Textract job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4bf094-8085-4392-ac57-639b9023a108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def get_s3_file_metadata(bucket_name, file_key):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "\n",
    "    response = s3.head_object(Bucket=bucket_name, Key=file_key)\n",
    "\n",
    "    # Extract the metadata from the response\n",
    "    metadata = response[\"Metadata\"]\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def start_analysis_jobs(s3_bucket, s3_object_keys):\n",
    "    client = boto3.client(\"textract\")\n",
    "    job_id_dict = {}\n",
    "\n",
    "    for key in s3_object_keys:\n",
    "        print(s3_bucket, key)\n",
    "        response = client.start_document_analysis(\n",
    "            DocumentLocation={\"S3Object\": {\"Bucket\": s3_bucket, \"Name\": key}},\n",
    "            FeatureTypes=[\"TABLES\"],\n",
    "        )\n",
    "\n",
    "        # Define the document source\n",
    "        document_source_location = f\"s3://{s3_bucket}/{key}\"\n",
    "\n",
    "        # Store the JobId for each s3 object key\n",
    "        job_id_dict[document_source_location] = {\n",
    "            \"s3_bucket\": s3_bucket,\n",
    "            \"s3_key\": key,\n",
    "            \"document_source\": document_source_location,\n",
    "            \"metadata\": get_s3_file_metadata(s3_bucket, key),\n",
    "            \"job_id\": response[\"JobId\"],\n",
    "        }\n",
    "\n",
    "    return job_id_dict\n",
    "\n",
    "\n",
    "def check_jobs_status(job_id_dict):\n",
    "    client = boto3.client(\"textract\")\n",
    "    unfinished_jobs = set([job[\"job_id\"] for job in job_id_dict.values()])\n",
    "\n",
    "    while unfinished_jobs:\n",
    "        print(f\"Documents being processed: {len(unfinished_jobs)}\\n\")\n",
    "        for job_id in list(\n",
    "            unfinished_jobs\n",
    "        ):  # We use list to avoid modifying the set during iteration\n",
    "            response = client.get_document_analysis(JobId=job_id)\n",
    "\n",
    "            status = response[\"JobStatus\"]\n",
    "            if status in [\"SUCCEEDED\", \"FAILED\"]:\n",
    "                unfinished_jobs.remove(job_id)\n",
    "\n",
    "        # To prevent rapidly hitting the API, we sleep for a short duration\n",
    "        time.sleep(5)\n",
    "\n",
    "    print(\"Finished all jobs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755d372-3013-4451-b5fa-6aa5b49e2c7e",
   "metadata": {},
   "source": [
    "#### Method to track progress of Textract job and to extract results from response\n",
    "The results for all pages are extracted and then those belonging to the same page are combined and put into chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cbf927-74be-4212-a2ac-7cc1b82413e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_job_results(job_id):\n",
    "    pages = {}\n",
    "    response = client.get_document_analysis(JobId=job_id)\n",
    "\n",
    "    for block in response[\"Blocks\"]:\n",
    "        if \"Page\" in block:\n",
    "            if block[\"Page\"] not in pages:\n",
    "                # If the page number has not been encountered yet, create a new list\n",
    "                pages[block[\"Page\"]] = []\n",
    "            pages[block[\"Page\"]].append(block)\n",
    "\n",
    "    next_token = None\n",
    "    if \"NextToken\" in response:\n",
    "        next_token = response[\"NextToken\"]\n",
    "\n",
    "    while next_token:\n",
    "        response = client.get_document_analysis(JobId=job_id, NextToken=next_token)\n",
    "\n",
    "        for block in response[\"Blocks\"]:\n",
    "            if \"Page\" in block:\n",
    "                if block[\"Page\"] not in pages:\n",
    "                    # If the page number has not been encountered yet, create a new list\n",
    "                    pages[block[\"Page\"]] = []\n",
    "                pages[block[\"Page\"]].append(block)\n",
    "\n",
    "        next_token = None\n",
    "        if \"NextToken\" in response:\n",
    "            next_token = response[\"NextToken\"]\n",
    "\n",
    "    # Convert dictionary to list for the return\n",
    "    # Here we are sorting the keys (page numbers) to ensure the list is in the correct order\n",
    "    pages_list = [pages[key] for key in sorted(pages.keys())]\n",
    "\n",
    "    return pages_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5399b1-a2d9-4228-96ad-4e9fb322811d",
   "metadata": {},
   "source": [
    "#### Helper method to determine how to group text to preserve reading order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b85685-82b6-4ca9-92e5-afc9c1c5f8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def detect_groups(lines):\n",
    "    # Convert the left positions of the lines to a 2D numpy array.\n",
    "    X = np.array([[line[1]] for line in lines])\n",
    "\n",
    "    # Check whether X is 2D\n",
    "    if len(X.shape) != 2:\n",
    "        return []\n",
    "\n",
    "    # Use the DBSCAN algorithm to cluster the lines into groups.\n",
    "    clustering = DBSCAN(eps=0.05, min_samples=1).fit(X)\n",
    "\n",
    "    # Initialize an empty list for each group.\n",
    "    groups = [[] for _ in range(max(clustering.labels_) + 1)]\n",
    "\n",
    "    # Assign each line to the appropriate group.\n",
    "    for i, line in enumerate(lines):\n",
    "        groups[clustering.labels_[i]].append(line)\n",
    "\n",
    "    # Sort groups by their leftmost position.\n",
    "    groups.sort(key=lambda group: min(line[1] for line in group))\n",
    "\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87902361-a131-4401-bc43-1177364fe9db",
   "metadata": {},
   "source": [
    "#### Method to extract the text from the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58fc911-2f8c-461c-bebd-6ed3ea316568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_text(blocks):\n",
    "    lines = []\n",
    "\n",
    "    for item in blocks:\n",
    "        if item[\"BlockType\"] == \"LINE\":\n",
    "            # Get the line text and its position.\n",
    "            text = item[\"Text\"]\n",
    "            left = item[\"Geometry\"][\"BoundingBox\"][\"Left\"]\n",
    "            top = item[\"Geometry\"][\"BoundingBox\"][\"Top\"]\n",
    "            lines.append((top, left, text))\n",
    "\n",
    "    # Detect groups.\n",
    "    groups = detect_groups(lines)\n",
    "\n",
    "    # Sort the lines in each group by their top position.\n",
    "    for group in groups:\n",
    "        group.sort(key=lambda x: x[0])  # sort by 'top' position\n",
    "\n",
    "    # Extract the sorted text.\n",
    "    text = \"\"\n",
    "    for group in groups:\n",
    "        for line in group:\n",
    "            text += line[2] + \"\\n\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f2421b-ad68-4cee-80f3-db2c5fed2640",
   "metadata": {},
   "source": [
    "#### Method to extract the tables from the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df0b31-f13b-43c0-b14b-b83bca3eb171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Helper method to extract text from cells\n",
    "def get_text(result, blocks_map):\n",
    "    text = \"\"\n",
    "    if \"Relationships\" in result:\n",
    "        for relationship in result[\"Relationships\"]:\n",
    "            if relationship[\"Type\"] == \"CHILD\":\n",
    "                for child_id in relationship[\"Ids\"]:\n",
    "                    word = blocks_map[child_id]\n",
    "                    if word[\"BlockType\"] == \"WORD\":\n",
    "                        text += word[\"Text\"] + \" \"\n",
    "                    if word[\"BlockType\"] == \"SELECTION_ELEMENT\":\n",
    "                        if word[\"SelectionStatus\"] == \"SELECTED\":\n",
    "                            text += \"X \"\n",
    "    return text\n",
    "\n",
    "\n",
    "# Helper method to determine table structure\n",
    "def get_rows_columns_map(table_result, blocks_map):\n",
    "    rows = {}\n",
    "    for relationship in table_result[\"Relationships\"]:\n",
    "        if relationship[\"Type\"] == \"CHILD\":\n",
    "            for child_id in relationship[\"Ids\"]:\n",
    "                cell = blocks_map[child_id]\n",
    "                if cell[\"BlockType\"] == \"CELL\":\n",
    "                    row_index = cell[\"RowIndex\"]\n",
    "                    col_index = cell[\"ColumnIndex\"]\n",
    "                    if row_index not in rows:\n",
    "                        # create new row\n",
    "                        rows[row_index] = {}\n",
    "\n",
    "                    # get the text value\n",
    "                    rows[row_index][col_index] = get_text(cell, blocks_map)\n",
    "    return rows\n",
    "\n",
    "\n",
    "# Helper method to create df from table\n",
    "def create_df(table_result, blocks_map):\n",
    "    rows = get_rows_columns_map(table_result, blocks_map)\n",
    "    data = []\n",
    "\n",
    "    # Iterate over rows\n",
    "    for row_index, cols in rows.items():\n",
    "        row = []\n",
    "        # Iterate over columns\n",
    "        for col_index, text in cols.items():\n",
    "            row.append(text)\n",
    "        data.append(row)\n",
    "\n",
    "    # Convert list of lists to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_tables(blocks):\n",
    "    blocks_map = {}\n",
    "    table_blocks = []\n",
    "    for block in blocks:\n",
    "        blocks_map[block[\"Id\"]] = block\n",
    "        if block[\"BlockType\"] == \"TABLE\":\n",
    "            table_blocks.append(block)\n",
    "\n",
    "    # Get the table extraction\n",
    "    dfs = []\n",
    "    if len(table_blocks) > 0:\n",
    "        for index, table in enumerate(table_blocks):\n",
    "            # Create the df\n",
    "            df = create_df(table, blocks_map)\n",
    "\n",
    "            # Process the extracted table\n",
    "            df = df.replace(\"\", np.nan)\n",
    "            df = df.dropna(axis=0, how=\"all\")\n",
    "            df = df.dropna(axis=1, how=\"all\")\n",
    "            df = df.replace(np.nan, \"\")\n",
    "            dfs.append(df.to_markdown())\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f799d-a154-4782-97b2-78e0fd84ee7f",
   "metadata": {},
   "source": [
    "#### Method to find all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06475df-0aff-4262-b34d-d3580f44b6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_files_in_s3_folder(bucket_name, folder_name=\"\"):\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=folder_name)\n",
    "\n",
    "    return [obj[\"Key\"] for obj in response[\"Contents\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbf9d4-8159-4ee7-8491-8c4423dabd6a",
   "metadata": {},
   "source": [
    "#### Methods to process the documents in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ff3e9-959d-43eb-a9fa-e11c9200db10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_document_results(job_description):\n",
    "    job_id = job_description[\"job_id\"]\n",
    "    document_name = job_description[\"s3_key\"].split(\"/\")[-1]\n",
    "    document_source_location = job_description[\"document_source\"]\n",
    "    document_metadata = job_description[\"metadata\"]\n",
    "\n",
    "    textract_response = get_job_results(job_id)\n",
    "\n",
    "    page_texts = [extract_text(blocks) for blocks in textract_response]\n",
    "    page_tables = [extract_tables(blocks) for blocks in textract_response]\n",
    "\n",
    "    if not len(page_texts) == len(page_tables):\n",
    "        raise Exception(\n",
    "            \"Something went wrong during processing, text and table lengths don't match\"\n",
    "        )\n",
    "\n",
    "    document_pages = []\n",
    "    for page_nr, (page_text, page_table_list) in enumerate(\n",
    "        zip(page_texts, page_tables)\n",
    "    ):\n",
    "        print(page_table_list)\n",
    "        document_pages.append(\n",
    "            {\"page\": page_nr, \"page_text\": page_text, \"page_tables\": page_table_list}\n",
    "        )\n",
    "\n",
    "    document = {\n",
    "        \"name\": document_name,\n",
    "        \"source_location\": document_source_location,\n",
    "        \"metadata\": document_metadata,\n",
    "        \"pages\": document_pages,\n",
    "    }\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcae585-0a7f-402d-b101-ca0e60642184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "\n",
    "def process_jobs_in_parallel(job_id_dict):\n",
    "    # Create a ThreadPoolExecutor. Adjust the max_workers parameter as needed.\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        # Use the executor to start a job for each job id.\n",
    "        # The executor will manage the threads and the jobs will run in parallel.\n",
    "        future_to_job_id = {\n",
    "            executor.submit(get_document_results, job_id_dict[key]): job_id_dict[key]\n",
    "            for key in job_id_dict.keys()\n",
    "        }\n",
    "\n",
    "        results = []\n",
    "        for future in concurrent.futures.as_completed(future_to_job_id):\n",
    "            job_id = future_to_job_id[future][\"job_id\"]\n",
    "            document_source_location = future_to_job_id[future][\"document_source\"]\n",
    "            try:\n",
    "                # If a job completed without raising an exception, its result is returned.\n",
    "                # If a job raised an exception, that exception is re-raised here.\n",
    "                result = future.result()\n",
    "            except Exception as exc:\n",
    "                print(\n",
    "                    f\"Job {job_id} generated an exception while trying to process document {document_source_location}:\\n {exc}\\n\"\n",
    "                )\n",
    "            else:\n",
    "                # Add the result to our results list.\n",
    "                print(f\"Finished processing document {document_source_location}.\\n\")\n",
    "                results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b23cc66-a2a5-4db0-adc0-6f0dcea0b136",
   "metadata": {},
   "source": [
    "## Run the extraction\n",
    "Make sure to have all of your PDF documents in a folder in an S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d90d75-da75-4bf1-ba8e-bddace2735d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# folder_name = 'financial_reports'\n",
    "s3_key = \"prepared_pdf_documents\"\n",
    "document_keys = list_files_in_s3_folder(S3_BUCKET_NAME, s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1a64e-6a64-46e4-b152-2a02dfa521eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "document_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1211594-0ab6-4e64-86da-8a494c7acecf",
   "metadata": {},
   "source": [
    "## Start the Textract analysis jobs and wait for them to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9db5c5-12b1-4b27-ad13-ef1feb3f55ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_id_dict = start_analysis_jobs(S3_BUCKET_NAME, document_keys)\n",
    "check_jobs_status(job_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b805cd-7f45-4355-8ad6-28f27673d84f",
   "metadata": {},
   "source": [
    "## Receive and process the results from Textract\n",
    "\n",
    "If any of the jobs generate an exception you can run `get_document_results(job_id_dict['s3://<your_document_url>'])` to get the Traceback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac49d22f-581d-41ac-a1f8-6bbda2537e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_processed = process_jobs_in_parallel(job_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f595c5c5-d4e1-4fbe-ab72-91e42ae13133",
   "metadata": {},
   "source": [
    "# Store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c84fc8-2936-428a-ae94-03328619929d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.helpers import store_list_to_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b970f0e-7f68-4dff-8df5-ab3cddac69d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We serialize and save the document processing results as a json to reuse in different jobs\n",
    "store_list_to_s3(S3_BUCKET_NAME, \"documents_processed.json\", documents_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a76c9-c13b-40df-bb66-860ae918a7c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 ls {S3_BUCKET_NAME}/documents_processed.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e6920-c362-4ce7-80b8-26fff7b878ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents_processed)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
